# -*- coding: utf-8 -*-
"""WrittenTextPred.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cUloX6d8RHutM3V-2H-r6WSfa_SjmXvD
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# for handling imbalancing
from imblearn.under_sampling import NearMiss
from keras.utils import np_utils

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report , confusion_matrix

import keras
from keras.models import Sequential
from keras.optimizers import Adam
from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization

# for learning rate decay
from keras.callbacks import ReduceLROnPlateau
from keras.models import Sequential
from keras.layers import Dense, Conv2D,MaxPooling2D, Flatten, Dropout, BatchNormalization
from keras.optimizers import SGD

import warnings
warnings.filterwarnings('ignore')


df = pd.read_csv('/content/A_Z Handwritten Data/A_Z Handwritten Data.csv')


# getting target variable
y = df['0']
del df['0']

x = y.replace([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25], ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',
'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'])


# Looking for imbalances in data
plt.figure(figsize = (10,5))
sns.countplot(x)

nM = NearMiss()
X_data, y_data = nM.fit_resample(df, y)

plt.figure(figsize = (10,5))
sns.countplot(y_data)

#One-Hot-Encoding of the target.
y = np_utils.to_categorical(y_data)
# Define the classification of 26 alphabets.
num_classes = y.shape[1]
num_classes



y.shape , X_data.shape

X_data = X_data / 255

X_data = np.array(X_data)
X_data = X_data.reshape(-1,28,28,1)
# Showing few images

f, ax = plt.subplots(2,5)
f.set_size_inches(10,10)
k = 0
for i in range(2):
    for j in range(5):
        ax[i,j].imshow(X_data[k].reshape(28,28), cmap='gray')
        k += 1
    plt.tight_layout()

X_train, X_test, y_train, y_test = train_test_split(X_data, y, test_size=0.2 ,random_state=102)

X_train.shape, X_test.shape, y_train.shape, y_test.shape


#Build an ordinary "Deep Learning" model with CNN and maxpooling by using Keras.
model = Sequential()
model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))
#Choose an optimizer and compile the model.
model.compile(optimizer = Adam(learning_rate = 0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])
#And print the summary of the model.
print(model.summary())

history = model.fit(X_train,y_train,epochs=50, batch_size=128, validation_data=(X_test,y_test))

# Final evaluation of the model
scores = model.evaluate(X_test,y_test, verbose=0)
print("CNN Error: %.2f%%" % (100-scores[1]*100))

model.save("model50epoach.h5")

"""Input Image
"""
 
from PIL import Image
img = Image.open("Figure_1.png").convert('L').resize((28, 28), Image.ANTIALIAS)
img = np.array(img)
x =model.predict(img[None,:,:])

print(x)

